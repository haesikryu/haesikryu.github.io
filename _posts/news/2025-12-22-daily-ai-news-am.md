---
categories:
- news
- ai
date: 2025-12-22 09:50:45 +0900
layout: post
tags:
- daily-news
- automation
- ai
title: 2025-12-22 Daily AI & Tech News
---

안녕하세요!

어제와 오늘 새벽 사이, AI 업계는 규제, 안전성, 그리고 파괴적인 새 모델 출시 소식으로 뜨거웠습니다. 특히 OpenAI는 개발자와 일반 사용자 모두를 위한 대형 업데이트를 연이어 발표했으며, 자율주행 분야에서는 충격적인 서비스 중단 소식이 전해졌습니다.

오늘의 가장 중요하고 흥미로운 AI & 테크 뉴스들을 정리해 드립니다.

***

# 코드 전쟁'의 시작? GPT-5.2-Codex 출시와 로보택시의 굴욕: 오늘 AI & 테크 뉴스 다이제스트

## 1. Waymo, 대규모 정전으로 샌프란시스코 서비스 일시 중단

**Summary:**
샌프란시스코에 대규모 정전 사태가 발생하자, Waymo의 로보택시 서비스가 토요일 저녁에 일시적으로 중단되었습니다. 정전으로 인해 많은 Waymo 차량이 도시 거리에 멈춰 서는 상황이 발생했습니다.

**Why it matters:**
자율주행 기술이 여전히 외부 환경(특히 전력망이나 통신망)에 얼마나 크게 의존하고 있는지 보여주는 사건입니다. 비상 상황이나 인프라 마비 시 로보택시가 단순한 ‘운송 수단’이 아닌 ‘운행을 멈춘 장애물’이 될 수 있다는 근본적인 안전성 문제를 다시 한번 상기시킵니다.

**Source:**
https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/

## 2. OpenAI, 최강의 코딩 모델 'GPT-5.2-Codex' 공개

**Summary:**
OpenAI가 자사의 가장 진보한 코딩 모델인 'GPT-5.2-Codex'를 출시했습니다. 이 모델은 장기적인 추론 능력, 대규모 코드 변환, 그리고 향상된 사이버 보안 기능을 제공하는 것을 목표로 합니다.

**Why it matters:**
코딩 AI 분야에서 독보적인 성능을 보여줄 것으로 예상됩니다. 특히 '장기 추론' 능력은 단순한 코드 조각 생성 수준을 넘어 복잡하고 구조적인 소프트웨어 프로젝트를 AI가 주도적으로 수행할 수 있게 되는 기반을 마련해 줍니다. 개발자 생산성 향상에 혁신적인 영향을 미칠 것입니다.

**Source:**
https://openai.com/index/introducing-gpt-5-2-codex

## 3. 뉴욕 주, AI 안전 규제 법안(RAISE Act) 통과

**Summary:**
캐시 호철 뉴욕 주지사가 AI 안전을 규제하기 위한 'RAISE Act'에 서명했습니다. 이 법안은 대형 AI 개발사들이 안전 프로토콜에 대한 정보를 공개하고, 안전 관련 사고 발생 시 72시간 이내에 주정부에 보고하도록 의무화합니다.

**Why it matters:**
미국 주 정부 차원에서 AI 안전 의무를 부과하는 강력한 규제 움직임이라는 점에서 중요합니다. 연방 차원의 규제가 지연되는 상황에서, 뉴욕이 선도적으로 AI 안전 및 투명성에 대한 기준을 제시하며 다른 주에도 영향을 미칠 수 있습니다.

**Source:**
https://techcrunch.com/2025/12/20/new-york-governor-kathy-hochul-signs-raise-act-to-regulate-ai-safety/

## 4. OpenAI, 내부 추론 모니터링 프레임워크 발표

**Summary:**
OpenAI는 '사고의 사슬(Chain-of-Thought)' 모니터링을 위한 새로운 프레임워크와 평가 도구를 발표했습니다. 연구 결과에 따르면, 모델이 도출하는 내부 추론 과정을 모니터링하는 것이 단순한 최종 결과물만 모니터링하는 것보다 AI 시스템의 제어 가능성(Scalable Control)을 높이는 데 훨씬 효과적입니다.

**Why it matters:**
AI 시스템의 안전성을 확보하는 데 있어 가장 중요한 기술적 진전 중 하나입니다. 모델의 능력이 더욱 커질수록 내부 작동 방식을 이해하고 통제하는 것이 필수적인데, 이 연구는 블랙박스처럼 여겨졌던 AI의 '생각'을 감시하고 조정할 수 있는 실질적인 경로를 제시합니다.

**Source:**
https://openai.com/index/evaluating-chain-of-thought-monitorability

## 5. ChatGPT, 이제 사용자가 '친절함' 수준 직접 조절 가능

**Summary:**
ChatGPT 사용자가 이제 챗봇의 '따뜻함(warmth)', '열정(enthusiasm)', 그리고 이모지 사용 빈도를 직접 조정할 수 있게 되었습니다.

**Why it matters:**
AI의 응답 스타일을 사용자 기호에 맞게 세밀하게 조정할 수 있게 됨으로써 사용자 경험(UX)이 크게 개선됩니다. 딱딱한 업무용 응답이 필요할 때와 편안하고 친근한 대화가 필요할 때 챗봇의 페르소나를 변경하여 활용도를 높일 수 있습니다.

**Source:**
https://techcrunch.com/2025/12/20/openai-allows-users-to-directly-adjust-chatgpts-warmth-and-enthusiasm/

## 6. OpenAI, 10대 사용자를 위한 모델 사양(Model Spec) 업데이트

**Summary:**
OpenAI는 모델 사양(Model Spec)에 18세 미만 사용자를 위한 새로운 원칙을 추가했습니다. 이 원칙은 발달 과학에 기반하여 10대에게 안전하고 연령에 적합한 지침을 제공하는 방법을 정의하며, 위험도가 높은 상황에서 모델이 지켜야 할 행동 기준을 명확히 합니다.

**Why it matters:**
AI 윤리와 안전 사용에 대한 책임이 강화되는 추세입니다. 젊은 사용자층이 AI에 노출되는 빈도가 높아짐에 따라, AI 개발사가 이들을 보호하기 위한 구체적이고 과학적인 기준을 마련했다는 점에서 의미가 있습니다.

**Source:**
https://openai.com/index/updating-model-spec-with-teen-protections

## 7. 구글, Gemini 앱에서 AI 생성 영상 검증 기능 확장

**Summary:**
구글이 콘텐츠 투명성 도구를 확장하여 이제 Gemini 앱에서도 AI로 생성되거나 편집된 영상의 출처를 확인할 수 있게 되었습니다. 이는 구글 AI(SynthID)를 통해 제작된 영상에 워터마크를 심어 쉽게 식별할 수 있도록 돕습니다.

**Why it matters:**
딥페이크 및 가짜 뉴스 확산을 막기 위한 필수적인 조치입니다. AI 콘텐츠의 신뢰도를 높이고 사용자가 어떤 내용이 AI에 의해 만들어진 것인지 명확히 알 수 있도록 투명성을 제공하는 데 기여합니다.

**Source:**
https://blog.google/technology/ai/verify-google-ai-videos-gemini-app/